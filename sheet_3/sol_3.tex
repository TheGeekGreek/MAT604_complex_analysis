\input{header.tex}

\title{Solutions Sheet 3}
\author{Yannis B\"{a}hni}
\address[Yannis B\"{a}hni]{University of Zurich, R\"{a}mistrasse 71, 8006 Zurich}
\email[Yannis B\"{a}hni]{\href{mailto:yannis.baehni@uzh.ch}{yannis.baehni@uzh.ch}}

\begin{document}
\maketitle
\thispagestyle{fancy}
\begin{enumerate}[label = \textbf{Exercise \arabic*.},wide = 0pt, itemsep=1.5ex]
	\item 
		Let $D \subseteq \mathbb{C}$ be non-empty and open in $\mathbb{C}$ and $f_1,f_2: D \to \mathbb{C}$ be real differentiable. Fix some $z_0 \in D$. Since $f_1$ and $f_2$ are real differentiable in $z_0$ there exists $\varphi_1,\varphi_2,\psi_1,\psi_2: D \to \mathbb{C}$ continuous at $z_0$ such that
				\begin{align}
					f_1(z) &= f_1(z_0) + (z - z_0)\varphi_1(z) + (\overline{z} - \overline{z_0})\psi_1(z)\label{eq:f_1}\\
					f_2(z) &= f_2(z_0) + (z - z_0)\varphi_2(z) + (\overline{z} - \overline{z_0})\psi_2(z)\label{eq:f_2}
				\end{align}
				\noindent for all $z \in D$.
		\begin{enumerate}[label = (\roman*),wide = 0pt, itemsep=1.5ex]
			\item Let $a,b \in \mathbb{C}$. Multiplying (\ref{eq:f_1}) by $a$, (\ref{eq:f_2}) by $b$ and adding both equations yields
				\begin{equation}
					af_1(z) + bf_2(z) = af_1(z_0) + bf_2(z_0) + (z - z_0)(a\varphi_1(z) + b\varphi_2(z)) + (\overline{z} - \overline{z_0})(a\psi_1(z) + b\psi_2(z))
					\label{eq:af_1+bf_2}
				\end{equation} 

				\noindent for all $z \in D$. Clearly, $a\varphi_1 + b \varphi_2$ and $a\psi_1 + b\psi_2$ are continuous functions in $z_0$ and from (\ref{eq:af_1+bf_2}) we deduce
				\begin{equation}
					\pd{(af_1 + bf_2)}{z}(z_0) = a\pd{f_1}{z}(z_0) + b\pd{f_2}{z}(z_0)
				\end{equation}

				\noindent and
				\begin{equation}
					\pd{(af_1 + bf_2)}{\overline{z}}(z_0) = a\pd{f_1}{\overline{z}}(z_0) + b\pd{f_2}{\overline{z}}(z_0).
				\end{equation}

				Since $z_0 \in D$ was arbitrary, we conclude
				\begin{equation}
					\pd{(af_1 + bf_2)}{z} = a\pd{f_1}{z} + b\pd{f_2}{z} \qquad \text{and} \qquad \pd{(af_1 + bf_2)}{\overline{z}} = a\pd{f_1}{\overline{z}} + b\pd{f_2}{\overline{z}}.
				\end{equation}

			\item Multiplying (\ref{eq:f_1}) and (\ref{eq:f_2}) yields
				\begin{align*}
					f_1f_2 = f_1(z_0)f_2(z_0) &+ (z - z_0) \sbr[0]{\varphi_1f_2(z_0) + f_1(z_0)\varphi_2 + (z - z_0)\varphi_1\varphi_2 + (\overline{z} - \overline{z_0})\psi_1\varphi_2}\\
					&+ (\overline{z} - \overline{z_0})\sbr[0]{\psi_1f_2(z_0) + f_1(z_0)\psi_2 + (z - z_0)\psi_2\varphi_1 + (\overline{z} - \overline{z_0})\psi_1\psi_2}
				\end{align*}

				\noindent where the argument $z$ is omitted. Clearly, the two functions in the square brackets are continuous at $z_0$ and evaluating them at $z_0$ yields
				\begin{equation}
					\pd{(f_1f_2)}{z}(z_0) = \pd{f_1}{z}(z_0)f_2(z_0) + f_1(z_0)\pd{f_2}{z}(z_0)
				\end{equation}
				\noindent and
				\begin{equation}
					\pd{(f_1f_2)}{\overline{z}}(z_0) = \pd{f_1}{\overline{z}}(z_0)f_2(z_0) + f_1(z_0)\pd{f_2}{\overline{z}}(z_0).
				\end{equation}

				Since $z_0 \in D$ was arbitrary, we conclude
				\begin{equation}
					\pd{(f_1f_2)}{z} = \pd{f_1}{z}f_2 + f_1\pd{f_2}{z} \qquad \text{and} \qquad \pd{(f_1f_2)}{\overline{z}} = \pd{f_1}{\overline{z}}f_2 + f_1\pd{f_2}{\overline{z}}.
				\end{equation}
			\item Conjugating (\ref{eq:f_1}) yields
				\begin{equation}
					\overline{f_1}(z) = \overline{f_1}(z_0) + (\overline{z} - \overline{z_0})\overline{\varphi_1}(z) + (z - z_0)\overline{\psi_1}(z).
					\label{eq:f_1_conj}
				\end{equation}

				From (\ref{eq:f_1_conj}) we deduce 
				\begin{equation}
					\pd{\overline{f_1}}{\overline{z}}(z_0) = \overline{\varphi_1}(z_0) = \overline{\frac{\partial f_1}{\partial z}}(z_0)
					\label{eq:conj}
				\end{equation}

				\noindent since $\varphi_1$ and $\psi_1$ are also continuous at $z_0$. Taking conjugates in (\ref{eq:conj}) and use that $z_0 \in D$ was arbitrary finally yields
				\begin{equation}
					\overline{\frac{\partial\overline{f_1}}{\partial\overline{z}}} = \pd{f_1}{z}.
				\end{equation}

			\item This follows directly from
				\begin{equation}
					z = z_0 + (z - z_0) \qquad \text{and} \qquad \overline{z} = \overline{z_0} + (\overline{z} - \overline{z_0}).
				\end{equation}

			\item See separate sheet.
			\item See separate sheet.
			\item Let $t_0 \in I$. The function $\varphi: I \to U \subseteq \mathbb{C}$ is differentiable if and only if there exists a function $\varphi_1: I \to U$ which is continuous at $t_0$ and such that
				\begin{equation}
					\varphi(t) = \varphi(t_0) + (t - t_0)\varphi_1(t)
					\label{eq:ordinary}
				\end{equation}

				\noindent for all $t \in I$ (this was proven in Analysis I). Furthermore there exists $f_1,f_2: U \to \mathbb{C}$ continuous at $\varphi(t_0)$ such that 
				\begin{equation}
					f(z) = f(\varphi(t_0)) + (z - \varphi(t_0))f_1(z) + (\overline{z} - \overline{\varphi(t_0)})f_2(z)
					\label{eq:f_1_ordinary}
				\end{equation}
				\noindent for all $z \in U$. Combining (\ref{eq:ordinary}) and (\ref{eq:f_1_ordinary}) yields
				\begin{align*}
					f(\varphi(t)) &= f(\varphi(t_0)) + (\varphi(t) - \varphi(t_0))f_1(z) + (\overline{\varphi(t)} - \overline{\varphi(t_0)})f_2(z)\\
					&= f(\varphi(t_0)) + (t - t_0)\sbr[0]{\varphi_1(t)f_1(\varphi(t)) + \overline{\varphi_1(t)}f_2(\varphi(t))}
				\end{align*}

				\noindent for all $t \in I$. Again, $\varphi_1(t)f(\varphi(t)) + \overline{\varphi_1(t)}f_2(\varphi(t))$ is clearly continuous at $t_0$ since composited functions are and thus we conclude
				\begin{equation}
					\od{(f \circ \varphi)}{t}(t_0) = \od{\varphi}{t}(t_0)\pd{f}{z}(\varphi(t_0)) + \frac{\d \overline{\varphi}}{\d t}(t_0)\pd{f}{\overline{z}}(\varphi(t_0)).
				\end{equation}

				Since $t_0 \in I$ was arbitrary we conclude
				\begin{equation}
					\od{(f \circ \varphi)}{t} = \od{\varphi}{t}\pd{f}{z} + \frac{\d \overline{\varphi}}{\d t}\pd{f}{\overline{z}}.
				\end{equation}
				\end{enumerate}

	\item We show the implications (i) $\Rightarrow$ (ii) $\Rightarrow$ (iii) $\Rightarrow$ (iv) $\Rightarrow$ (i). Since the proofs are of a relatively simple nature, we focus on the formal part. The complex numbers $\mathbb{C}$ are a vector space over $\mathbb{R}$ (as a field extension). So the situation of the exercise can be sumarized by the following commutative diagram:
		\[
			\xymatrix@=2cm{
				\mathbb{C} \ar[r]^T &\mathbb{C}\\
				\mathbb{R}^2 \ar[u]^{\Phi_B} \ar[r]_{M_B(T)} &\mathbb{R}^2 \ar[u]_{\Phi_B}}
	 	\]
		\noindent where $T$ is $\mathbb{R}$-linear, $\Phi_B$ denotes the basis-isomorphism which is in this case given by $\Phi_B(x,y) := x + iy$ and $M_B(T)$ is defined by
		\begin{equation}
			\begin{pmatrix}
				x\\
				y
			\end{pmatrix} \mapsto
			\begin{pmatrix}
				a & b\\
				c & d
			\end{pmatrix}
			\begin{pmatrix}
				x\\
				y
			\end{pmatrix}.
		\end{equation}
		The first implication is evident by the definition of $\mathbb{C}$-linearity. Assume that (ii) holds. By 
		\begin{equation}
			T(i) = (\Phi_B \circ M_B(T) \circ \Phi_B^{-1})(i) = b + id
		\end{equation}
		\noindent and
		\begin{equation}
			iT(1) = i(\Phi_B \circ M_B(T) \circ \Phi_B^{-1})(1) = i(a + ic) = -c + ia 
		\end{equation}

		\noindent we get the requirement $b + id = -c + ia$. Hence $b = -c$ and $a = d$. Assume that (iii) holds. Then we have for $z := x + iy \in \mathbb{C}$
		\begin{equation}
			T(z) = (\Phi_B \circ M_B(T) \circ \Phi_B^{-1})(x + iy) = (ax - cy) + i(cx + ay) = (a + ic)z.
		\end{equation}

		Finally, assume that (iv) holds. Then $T$ is clearly $\mathbb{C}$-linear since 
		\begin{equation}
			T(\lambda z + w) = (a + ic)(\lambda z + w) = \lambda(a + ic)z + (a + ic)w = \lambda T(z) + T(w)
		\end{equation}

		\noindent for $\lambda,z,w \in \mathbb{C}$.

	\item See separate sheet.

	\item We show this in two steps: first $\liminf_{\nu \to \infty}\abs[0]{a_\nu}/\abs[0]{a_{\nu + 1}} \leq R$ and second $R \leq \limsup_{\nu \to \infty}\abs[0]{a_\nu}/\abs[0]{a_{\nu + 1}}$. Define 
		\begin{equation}
			S := \liminf_{\nu \to \infty}\frac{\abs[0]{a_\nu}}{\abs[0]{a_{\nu + 1}}} \qquad \text{and} \qquad T := \limsup_{\nu \to \infty}\frac{\abs[0]{a_\nu}}{\abs[0]{a_{\nu + 1}}}.
		\end{equation}

		If $S = 0$ there is nothing to prove. First we assume that $0 < S < \infty$. Since $a_\nu \neq $ for almost all $\nu \in \mathbb{N}$ we find $\nu_0'$ such that $a_\nu \neq 0$ for all $\nu \geq \nu_0'$. For any $\varepsilon > 0$ we find $v_0 \in \mathbb{N}$, $\nu_0 \geq \nu_0'$ such that
		\begin{equation}
			\abs[3]{\inf_{\mu \geq \nu}\cbr[3]{\frac{\abs[0]{a_\mu}}{\abs[0]{a_{\mu + 1}}}} - S} < \varepsilon \qquad \forall \nu \geq \nu_0
			\label{eq:est_inf}
		\end{equation}

		Setting $\nu = \nu_0$ in (\ref{eq:est_inf}) yields 
		\begin{equation}
			S - \varepsilon < \frac{\abs[0]{a_\nu}}{\abs[0]{a_{\nu + 1}}}  \qquad \forall \nu \geq \nu_0.
			\label{eq:est_equi}
		\end{equation}

		Now let $0 < \varepsilon < S$.

		\begin{lemma}
			For all $\nu \geq \nu_0$ we have $\abs[0]{a_\nu}(S - \varepsilon)^\nu \leq \abs[0]{a_{\nu_0}}(S - \varepsilon)^{\nu_0}$.
			\label{lem:ind}
		\end{lemma}

		\begin{proof}
			Proof by induction on $\nu \geq \nu_0$. The case $\nu = \nu_0$ is clear. By (\ref{eq:est_equi}) we have that
			\begin{equation}
				\abs[0]{a_{\nu + 1}}(S - \varepsilon)^{\nu + 1} = 	\abs[0]{a_{\nu + 1}}(S - \varepsilon)^{\nu}(S - \varepsilon) \leq \abs[0]{a_\nu}(S - \varepsilon)^\nu \leq \abs[0]{a_{\nu_0}}(S - \varepsilon)^{\nu_0}.  
			\end{equation}
		\end{proof}

		Hence 
		\begin{equation}
			\abs[0]{a_\nu}(S - \varepsilon)^\nu \leq \max\cbr[0]{\abs[0]{a_0},\dots,\abs[0]{a_{\nu_0 - 1}}(S - \varepsilon)^{\nu_0 -1},\abs[0]{a_{\nu_0}}(S - \varepsilon)^{\nu_0}} \qquad \forall \nu \in \mathbb{N}.
			\label{eq:bound}
		\end{equation}

		Taking the limit $\varepsilon \searrow 0$ on inequality (\ref{eq:bound}) yields
		\begin{equation}
			\abs[0]{a_\nu}S^\nu \leq \max\cbr[0]{\abs[0]{a_0},\dots,\abs[0]{a_{\nu_0 - 1}}S^{\nu_0 -1},\abs[0]{a_{\nu_0}}S^{\nu_0}} \qquad \forall \nu \in \mathbb{N}
		\end{equation}

		\noindent and thus
		\begin{equation}
			S \leq R.
		\end{equation}

		Now we consider the case $S = \infty$. By definition, for every $M > 0$ we find $\nu_0 \in \mathbb{N}$, $\nu_0 \geq \nu_0'$ such that 
		\begin{equation}
			\inf_{\mu \geq \nu}\cbr[3]{\frac{\abs[0]{a_\mu}}{\abs[0]{a_{\mu + 1}}}} > M \qquad \forall \nu \geq \nu_0.
		\end{equation}

		Again, this is equivalent to
		\begin{equation}
			 M < \frac{\abs[0]{a_\nu}}{\abs[0]{a_{\nu + 1}}} \qquad \forall \nu \geq \nu_0.
		\end{equation}

		Similarly to the statement of lemma \ref{lem:ind} one proves that 
		\begin{equation}
			\abs[0]{a_\nu}M^\nu \leq \abs[0]{a_{\nu_0}}M^{\nu_0} \qquad \forall \nu \geq \nu_0.
		\end{equation}

		Hence
		\begin{equation}
			\abs[0]{a_\nu}M^\nu \leq \max\cbr[0]{a_0,\dots,a_{\nu_0 - 1}M^{\nu_0 - 1},\abs[0]{a_{\nu_0}}M^{\nu_0}} \qquad \forall M > 0.
		\end{equation}

		Thus the sequence $(\abs[0]{a_\nu}M^\nu)_{\nu \in \mathbb{N}}$ is bounded for any $M > 0$ which implies $R = \infty$.\\
		If $T = \infty$ there is nothing to prove. So assume $0 < T < \infty$. Fix $ \varepsilon > 0$. By the definition of the limit superior we find an index $\nu_0 \in \mathbb{N}$, $\nu_0 \geq \nu_0'$, such that
		\begin{equation}
			\abs[3]{\sup_{\mu \geq \nu}\cbr[3]{\frac{\abs[0]{a_\mu}}{\abs[0]{a_{\mu + 1}}}} - T} < \varepsilon \qquad \forall \nu \geq \nu_0.
			\label{eq:est_sup}
		\end{equation}

		Estimate (\ref{eq:est_sup}) is equivalent to
		\begin{equation}
			\frac{\abs[0]{a_\nu}}{\abs[0]{a_{\nu + 1}}} < T + \varepsilon \qquad \forall \nu \geq \nu_0.
			\label{est:eq_sup}
		\end{equation}

		We have an analogous version of lemma \ref{lem:ind}.
		\begin{lemma}
			For all $\nu \geq \nu_0$ we have $\abs[0]{a_\nu}(T + \varepsilon)^\nu \geq \abs[0]{a_{\nu_0}}(T + \varepsilon)^{\nu_0}$.
			\label{lem:sup}
		\end{lemma}

		\begin{proof}
			Proof by induction on $\nu \geq \nu_0$. If $\nu = \nu_0$ there is nothing to prove. Furthermore, estimate (\ref{est:eq_sup}) implies
			\begin{equation}
				\abs[0]{a_{\nu + 1}}(T + \varepsilon)^{\nu + 1} \geq \abs[0]{a_{\nu}}(T + \varepsilon)^{\nu} \geq \abs[0]{a_{\nu_0}}(T + \varepsilon)^{\nu_0}.
			\end{equation}
		\end{proof} 

		An immediate consequence of lemma \ref{lem:sup} is that if $T \neq 0$ we have that $(\abs[0]{a_\nu}T^\nu)_{\nu \in \mathbb{N}} \not\to 0$ (take the limit $\varepsilon \searrow 0$). So $T + z_0 \in \mathbb{C} \setminus B_R(z_0)$, which immediately implies $T \geq R$. Finally we consider the case $T = 0$.

\end{enumerate}
%\originalsectionstyle
\printbibliography
\end{document}
